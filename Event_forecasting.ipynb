{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Activity Prediciton"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Split_functions import data_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pm4py as pm4\n",
    "\n",
    "import plotly.express as px\n",
    "from xgboost import XGBClassifier\n",
    "from hyperopt import hp, tpe, Trials, fmin, space_eval, STATUS_OK\n",
    "import pickle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downoalding the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pm4.convert_to_dataframe(pm4.read.read_xes('BPI_Challenge_2012.xes.gz'))\n",
    "df = pd.read_csv('cleaned_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "- Discovering new variables: next_activity, previous_activity1,2,3,4,5\n",
    "- Label encoding discovered variables to put into XGBoost and Random Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['next_activity'] = df.groupby('case:concept:name')['concept:name'].shift(-1)\n",
    "df['previous_activity1'] = df.groupby('case:concept:name')['concept:name'].shift(1)\n",
    "df['previous_activity2'] = df.groupby('case:concept:name')['concept:name'].shift(2)\n",
    "df['previous_activity3'] = df.groupby('case:concept:name')['concept:name'].shift(3)\n",
    "df['previous_activity4'] = df.groupby('case:concept:name')['concept:name'].shift(4)\n",
    "df['previous_activity5'] = df.groupby('case:concept:name')['concept:name'].shift(5)\n",
    "\n",
    "le = LabelEncoder()\n",
    "df['current_activity_encoded'] = le.fit_transform(df['concept:name'])\n",
    "df['next_activity_encoded'] = le.fit_transform(df['next_activity'])\n",
    "df['previous_activity1_encoded'] = le.fit_transform(df['previous_activity1'])\n",
    "df['previous_activity2_encoded'] = le.fit_transform(df['previous_activity2'])\n",
    "df['previous_activity3_encoded'] = le.fit_transform(df['previous_activity3'])\n",
    "df['previous_activity4_encoded'] = le.fit_transform(df['previous_activity4'])\n",
    "df['previous_activity5_encoded'] = le.fit_transform(df['previous_activity5'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = df[['current_activity_encoded', \n",
    "                'previous_activity1_encoded', \n",
    "                'previous_activity2_encoded', \n",
    "                'previous_activity3_encoded',\n",
    "                'previous_activity4_encoded',\n",
    "                'previous_activity5_encoded',\n",
    "                'case:concept:name', \n",
    "                'time:timestamp']]\n",
    "target = df[['next_activity_encoded', 'case:concept:name', 'time:timestamp']]\n",
    "train_size = 0.8\n",
    "\n",
    "X, X_test, y, y_test = data_split(predictor, target, train_size)\n",
    "\n",
    "print('+----------------------------------------------------------------+')\n",
    "print('After cleaning traces!')\n",
    "print('Training dataset max time:',X['time:timestamp'].max())\n",
    "print('Testing dataset min time:', X_test['time:timestamp'].min())\n",
    "print('+----------------------------------------------------------------+')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next action prediction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taking only necessary columns for the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_features = ['current_activity_encoded', \n",
    "       'previous_activity1_encoded', \n",
    "       'previous_activity2_encoded', \n",
    "       'previous_activity3_encoded',\n",
    "       'previous_activity4_encoded',\n",
    "       'previous_activity5_encoded',\n",
    "       'case:concept:name']\n",
    "y_features = ['next_activity_encoded',\n",
    "              'case:concept:name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[X_features]\n",
    "X_test = X_test[X_features]\n",
    "y = y[y_features]\n",
    "y_test = y_test[y_features]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reset_index(drop = True)\n",
    "y = y.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the search space for hyperparameters\n",
    "space = {\n",
    "    'n_estimators': hp.choice('n_estimators', [int(x) for x in np.linspace(start = 5, stop = 100, num = 60)]),\n",
    "    'max_depth': hp.choice('max_depth', [5, 6, 7, 9, 10, 12, 13, 15, 16, 17, 19, 20, 22, 23, 25]),\n",
    "    'min_samples_split': hp.choice('min_samples_split', [2, 5, 10]),\n",
    "    'min_samples_leaf': hp.choice('min_samples_leaf', [1, 2, 4, 6, 8])\n",
    "}\n",
    "\n",
    "# Initialize variables to store results\n",
    "best_params_rc_list = []\n",
    "best_scores_list = []\n",
    "\n",
    "# Number of folds\n",
    "n = 10\n",
    "\n",
    "# Custom Nested K-fold cross validation\n",
    "start = 0\n",
    "end = len(X)\n",
    "step_size = end//n\n",
    "\n",
    "train_start = 0 \n",
    "train_end = end - step_size\n",
    "\n",
    "test_start = train_end\n",
    "test_end = end\n",
    "\n",
    "# outer k-fold\n",
    "for i in range(n):\n",
    "    if train_start == test_start:\n",
    "        train_x = X.loc[test_end+1:]\n",
    "        train_y = y.loc[test_end+1:]\n",
    "\n",
    "        test_x = X.loc[test_start:test_end]\n",
    "        test_y = y.loc[test_start:test_end]\n",
    "\n",
    "    else:\n",
    "        if test_end + 1 >= len(X):\n",
    "            train_x = X.loc[train_start:train_end-1]\n",
    "            train_y = y.loc[train_start:train_end-1]\n",
    "        else:\n",
    "            train_x = pd.concat([X.loc[train_start:train_end-1], X.loc[test_end+1:]])\n",
    "            train_y = pd.concat([y.loc[train_start:train_end-1], y.loc[test_end+1:]])\n",
    "\n",
    "        test_x = X.loc[test_start:test_end]\n",
    "        test_y = y.loc[test_start:test_end]\n",
    "    \n",
    "    overlapping_sets = list(set(train_x['case:concept:name'].unique()).intersection(set(test_x['case:concept:name'].unique())))\n",
    "    # # Clean train\n",
    "    X_train = train_x[train_x['case:concept:name'].isin([overlapping_sets]) == False]\n",
    "    y_train = train_y[train_y['case:concept:name'].isin(train_x['case:concept:name'].unique())]\n",
    "    \n",
    "    # # Clean test\n",
    "    X_validation = test_x[test_x['case:concept:name'].isin([overlapping_sets]) == False]\n",
    "    y_validation = test_y[test_y['case:concept:name'].isin(test_x['case:concept:name'].unique())]\n",
    "\n",
    "    # # Finalizing the data\n",
    "    X_train = X_train[X_features[:-1]].values\n",
    "    X_validation = X_validation[X_features[:-1]].values\n",
    "    y_train = y_train[y_features[0]].values\n",
    "    y_validation = y_validation[y_features[0]].values\n",
    "    \n",
    "\n",
    "    # Define a function to optimize using Hyperopt (inner k-fold)\n",
    "    def objective(params):\n",
    "        rfc = RandomForestClassifier(**params, n_jobs = -1)\n",
    "        rfc.fit(X_train, np.ravel(y_train))\n",
    "        score = rfc.score(X_validation, y_validation)\n",
    "        return {'loss': -score, 'status': STATUS_OK}\n",
    "    \n",
    "    # Define Trials object to store optimization results\n",
    "    trials = Trials()\n",
    "    \n",
    "    # Use Hyperopt to find the best hyperparameters\n",
    "    best = fmin(objective, space, algo=tpe.suggest, max_evals=100, trials=trials, return_argmin=False)\n",
    "    \n",
    "    # Store the best parameters and corresponding score\n",
    "    best_params_rc_list.append(best)\n",
    "    best_scores_list.append(-trials.best_trial['result']['loss'])  # Convert back to positive\n",
    "    \n",
    "    \n",
    "    test_end = test_start\n",
    "    train_end -= step_size\n",
    "    test_start = train_end\n",
    "\n",
    "#Print the best parameters and average score across all outer folds\n",
    "print(\"Best Parameters:\")\n",
    "for params in best_params_rc_list:\n",
    "    print(params)\n",
    "print(\"Average Score:\", np.mean(best_scores_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving trained models to pickle format to easily retrieve them later\n",
    "count = 1\n",
    "for i in best_params_rc_list:\n",
    "    model = RandomForestClassifier(**i)\n",
    "    model.fit(X[X_features[:-1]].values, np.ravel(y[y_features[0]].values))\n",
    "    print(f\"Model {count} with scores: \",model.score(X_test[X_features[:-1]].values, y_test[y_features[0]].values), 'saved!')\n",
    "    \n",
    "    pickle.dump(model , open(f'next_activity_prediction_rfc_{count}.pk1' , 'wb'))\n",
    "    count+=1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting (Choose XGBoost or LightGBM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the search space for hyperparameters\n",
    "space = {\n",
    "    'n_estimators': hp.choice('n_estimators', [int(x) for x in np.linspace(start = 5, stop = 50, num = 45)]),\n",
    "    'max_depth': hp.choice('max_depth', [int(i) for i in range(3,11)]),\n",
    "    'learning_rate': hp.uniform('learning_rate', 0.01, 0.3),\n",
    "    'subsample': hp.uniform('subsample', 0.6, 1.0),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.6, 1.0),\n",
    "    'gamma': hp.uniform('gamma', 0, 0.2)\n",
    "}\n",
    "\n",
    "# Initialize variables to store results\n",
    "best_params_xgbc_list = []\n",
    "best_scores_list = []\n",
    "\n",
    "# Number of folds\n",
    "n = 10\n",
    "\n",
    "# Custom Nested K-fold cross validation\n",
    "start = 0\n",
    "end = len(X)\n",
    "step_size = end//n\n",
    "\n",
    "train_start = 0 \n",
    "train_end = end - step_size\n",
    "\n",
    "test_start = train_end\n",
    "test_end = end\n",
    "\n",
    "# outer k-fold\n",
    "for i in range(n):\n",
    "    if train_start == test_start:\n",
    "        train_x = X.loc[test_end+1:]\n",
    "        train_y = y.loc[test_end+1:]\n",
    "\n",
    "        test_x = X.loc[test_start:test_end]\n",
    "        test_y = y.loc[test_start:test_end]\n",
    "\n",
    "    else:\n",
    "        if test_end + 1 >= len(X):\n",
    "            train_x = X.loc[train_start:train_end-1]\n",
    "            train_y = y.loc[train_start:train_end-1]\n",
    "        else:\n",
    "            train_x = pd.concat([X.loc[train_start:train_end-1], X.loc[test_end+1:]])\n",
    "            train_y = pd.concat([y.loc[train_start:train_end-1], y.loc[test_end+1:]])\n",
    "\n",
    "        test_x = X.loc[test_start:test_end]\n",
    "        test_y = y.loc[test_start:test_end]\n",
    "    \n",
    "    overlapping_sets = list(set(train_x['case:concept:name'].unique()).intersection(set(test_x['case:concept:name'].unique())))\n",
    "    # # Clean train\n",
    "    X_train = train_x[train_x['case:concept:name'].isin([overlapping_sets]) == False]\n",
    "    y_train = train_y[train_y['case:concept:name'].isin(train_x['case:concept:name'].unique())]\n",
    "    \n",
    "    # # Clean test\n",
    "    X_validation = test_x[test_x['case:concept:name'].isin([overlapping_sets]) == False]\n",
    "    y_validation = test_y[test_y['case:concept:name'].isin(test_x['case:concept:name'].unique())]\n",
    "\n",
    "    # # Finalizing the data\n",
    "    X_train = X_train[X_features[:-1]].values\n",
    "    X_validation = X_validation[X_features[:-1]].values\n",
    "    y_train = y_train[y_features[0]].values\n",
    "    y_validation = y_validation[y_features[0]].values\n",
    "    \n",
    "    # Define a function to optimize using Hyperopt (inner K-fold)\n",
    "    def objective(params):\n",
    "        xgb = XGBClassifier(**params)\n",
    "        xgb.fit(X_train, y_train)\n",
    "        score = xgb.score(X_validation, y_validation)\n",
    "        return {'loss': -score, 'status': STATUS_OK}\n",
    "    \n",
    "    # Define Trials object to store optimization results\n",
    "    trials = Trials()\n",
    "    \n",
    "    # Use Hyperopt to find the best hyperparameters\n",
    "    best = fmin(objective, space, algo=tpe.suggest, max_evals=10, trials=trials, return_argmin=False)\n",
    "    \n",
    "    # Store the best parameters and corresponding score\n",
    "    best_params_xgbc_list.append(best)\n",
    "    best_scores_list.append(-trials.best_trial['result']['loss'])  # Convert back to positive\n",
    "    \n",
    "    \n",
    "    test_end = test_start\n",
    "    train_end -= step_size\n",
    "    test_start = train_end\n",
    "\n",
    "#Print the best parameters and average score across all outer folds\n",
    "print(\"Best Parameters:\")\n",
    "for params in best_params_xgbc_list:\n",
    "    print(params)\n",
    "print(\"Average Score:\", np.mean(best_scores_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing trained models in pickle format to easily retrieve them later\n",
    "count = 1\n",
    "for i in best_params_xgbc_list:\n",
    "    model = XGBClassifier(**i)\n",
    "    model.fit(X[X_features[:-1]].values, np.ravel(y[y_features[0]].values))\n",
    "    print(f\"Model {count}\",model.score(X_test[X_features[:-1]].values, y_test[y_features[0]].values), 'successfully saved!')\n",
    "    pickle.dump(model, open(f'next_activity_prediction_xgbc_{count}.pk1', 'wb'))\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
