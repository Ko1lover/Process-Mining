{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pm4py as pm4\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "import pickle\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from hyperopt import hp, tpe, Trials, fmin, space_eval, STATUS_OK\n",
    "from Split_functions import data_split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('cleaned_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieving month/day/weekday/hour and if its a holiday or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['time:timestamp'] = pd.to_datetime(df['time:timestamp'], format = 'mixed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hour'] = df['time:timestamp'].dt.hour\n",
    "df['day'] = df['time:timestamp'].dt.day\n",
    "df['month'] = df['time:timestamp'].dt.month\n",
    "df['weekday'] = df['time:timestamp'].dt.strftime(\"%A\")\n",
    "df['is_holiday'] = 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating new column working hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_hours = df.groupby('hour').count()\n",
    "work_hours['percentage'] = work_hours['concept:name'].apply(lambda x : x/sum(work_hours['concept:name'])*100)\n",
    "work_hours_list = work_hours[work_hours['percentage']>1].reset_index()['hour'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determining if it is the working hours or not\n",
    "df['work_hour'] = df['hour'].apply(lambda x: 1 if x in(work_hours_list) else 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding holidays "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Typical weekends\n",
    "df.loc[(df['weekday'] == 'Sunday') | (df['weekday'] == 'Saturday'), 'is_holiday'] = 1\n",
    "\n",
    "# New Year's Day\n",
    "df.loc[(df['day'] == 1) & (df['month'] == 1), 'is_holiday'] = 1\n",
    "\n",
    "# Christmas Day \n",
    "df.loc[((df['day'].isin([i for i in range(22, 27)]))) & (df['month'] == 1), 'is_holiday'] = 1\n",
    "\n",
    "# Good Friday, Easter \n",
    "df.loc[(df['day'].isin([i for i in range(6,10)])) & (df['month'] == 4), 'is_holiday'] = 1\n",
    "\n",
    "# King's day (27 April)\n",
    "df.loc[(df['day'] == 27) & (df['month'] == 4), 'is_holiday'] = 1\n",
    "\n",
    "# Liberation Day\n",
    "df.loc[(df['day'] == 5) & (df['month'] == 5), 'is_holiday'] = 1\n",
    "\n",
    "# Ascension Day \n",
    "df.loc[(df['day'].isin([i for i in range(17, 21)])) & (df['month'] == 5), 'is_holiday'] = 1\n",
    "\n",
    "# Pentecost\n",
    "df.loc[(df['day'].isin([i for i in range(26, 29)])) & (df['month'] == 5), 'is_holiday'] = 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieving time delta between events and applying logarithmic normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['current_time_delta'] = df.groupby('case:concept:name')['time:timestamp'].diff(-1).dt.total_seconds().abs()\n",
    "df['logged_current_time_delta'] = np.log(df['current_time_delta'] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clown = df.groupby('case:concept:name').count().sort_values(by = 'concept:name')\n",
    "needed_ids = clown[clown['concept:name'] <= 82].reset_index()['case:concept:name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['case:concept:name'].isin(needed_ids)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieving time lags of previous events and previous activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['next_activity_time'] = df.groupby('case:concept:name')['logged_current_time_delta'].shift(-1)\n",
    "df['lag1'] = df.groupby('case:concept:name')['logged_current_time_delta'].shift(1)\n",
    "df['lag2'] = df.groupby('case:concept:name')['logged_current_time_delta'].shift(2)\n",
    "df['lag3'] = df.groupby('case:concept:name')['logged_current_time_delta'].shift(3)\n",
    "df['lag4'] = df.groupby('case:concept:name')['logged_current_time_delta'].shift(4)\n",
    "df['lag5'] = df.groupby('case:concept:name')['logged_current_time_delta'].shift(5)\n",
    "\n",
    "df['previous_activity1'] = df.groupby('case:concept:name')['concept:name'].shift(1)\n",
    "df['previous_activity2'] = df.groupby('case:concept:name')['concept:name'].shift(2)\n",
    "df['previous_activity3'] = df.groupby('case:concept:name')['concept:name'].shift(3)\n",
    "df['previous_activity4'] = df.groupby('case:concept:name')['concept:name'].shift(4)\n",
    "df['previous_activity5'] = df.groupby('case:concept:name')['concept:name'].shift(5)\n",
    "\n",
    "\n",
    "# df = pd.get_dummies(df, columns=['case:concept:name', 'previous_activity1', 'previous_activity2', 'previous_activity3', 'previous_activity4','previous_activity5'], dtype = int)\n",
    "le = LabelEncoder()\n",
    "df['current_activity_encoded'] = le.fit_transform(df['concept:name'])\n",
    "df['previous_activity1_encoded'] = le.fit_transform(df['previous_activity1'])\n",
    "df['previous_activity2_encoded'] = le.fit_transform(df['previous_activity2'])\n",
    "df['previous_activity3_encoded'] = le.fit_transform(df['previous_activity3'])\n",
    "df['previous_activity4_encoded'] = le.fit_transform(df['previous_activity4'])\n",
    "df['previous_activity5_encoded'] = le.fit_transform(df['previous_activity5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.get_dummies(df, columns=['concept:name', 'previous_activity1', 'previous_activity2', 'previous_activity3', 'previous_activity4','previous_activity5'], dtype = int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(1e-6)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data on train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = df[['logged_current_time_delta', \n",
    "                'current_activity_encoded', 'previous_activity1_encoded', 'previous_activity2_encoded', \n",
    "                'previous_activity3_encoded', 'previous_activity4_encoded', 'previous_activity5_encoded',\n",
    "                'lag1', 'lag2', 'lag3', 'lag4', 'lag5',\n",
    "                'work_hour', 'is_holiday', 'month', 'case:concept:name', 'time:timestamp']]\n",
    "target = df[['next_activity_time', 'case:concept:name', 'time:timestamp']]\n",
    "train_size = 0.8\n",
    "\n",
    "X, X_test, y, y_test = data_split(predictor, target, train_size)\n",
    "\n",
    "print('+----------------------------------------------------------------+')\n",
    "print('After cleaning traces!')\n",
    "print('Training dataset max time:',X['time:timestamp'].max())\n",
    "print('Testing dataset min time:', X_test['time:timestamp'].min())\n",
    "print('+----------------------------------------------------------------+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_features = ['logged_current_time_delta', \n",
    "                'current_activity_encoded', 'previous_activity1_encoded', 'previous_activity2_encoded', \n",
    "                'previous_activity3_encoded', 'previous_activity4_encoded', 'previous_activity5_encoded',\n",
    "                'lag1', 'lag2', 'lag3', 'lag4', 'lag5',\n",
    "                'work_hour', 'is_holiday', 'month', 'case:concept:name']\n",
    "\n",
    "y_features = ['next_activity_time', 'case:concept:name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_features_to_train = ['logged_current_time_delta', \n",
    "                'current_activity_encoded', 'previous_activity1_encoded', 'previous_activity2_encoded', \n",
    "                'previous_activity3_encoded', 'previous_activity4_encoded', 'previous_activity5_encoded',\n",
    "                'lag1', 'lag2', 'lag3', 'lag4', 'lag5',\n",
    "                'work_hour', 'is_holiday', 'month']\n",
    "\n",
    "y_features_to_train = ['next_activity_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[X_features]\n",
    "X_test = X_test[X_features]\n",
    "y = y[y_features]\n",
    "y_test = y_test[y_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reset_index(drop = True)\n",
    "y = y.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# showcase a distribution of the time till next activity\n",
    "# put np.log on the time till next activity in order to get a better distribution\n",
    "# one hot encoding for features, as well put their order in the trace\n",
    "# put instead of nan values the 1e6 (just a really small value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(df['current_time_delta'], opacity = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(df['logged_current_time_delta'], opacity = 0.2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the search space for hyperparameters\n",
    "space = {\n",
    "    'n_estimators': hp.choice('n_estimators', [int(x) for x in np.linspace(start = 5, stop = 100, num = 60)]),\n",
    "    'max_depth': hp.choice('max_depth', [5, 6, 7, 9, 10, 12, 13, 15, 16, 17, 19, 20, 22, 23, 25]),\n",
    "    'min_samples_split': hp.choice('min_samples_split', [2, 5, 10]),\n",
    "    'min_samples_leaf': hp.choice('min_samples_leaf', [2, 4, 6, 8])\n",
    "}\n",
    "\n",
    "# Initialize variables to store results\n",
    "best_params_rfr_list = []\n",
    "best_scores_list = []\n",
    "\n",
    "n = 10\n",
    "\n",
    "start = 0\n",
    "end = len(X)\n",
    "step_size = end//n\n",
    "\n",
    "train_start = 0 \n",
    "train_end = end - step_size\n",
    "\n",
    "test_start = train_end\n",
    "test_end = end\n",
    "\n",
    "for i in range(n):\n",
    "    if train_start == test_start:\n",
    "        train_x = X.loc[test_end+1:]\n",
    "        train_y = y.loc[test_end+1:]\n",
    "\n",
    "        test_x = X.loc[test_start:test_end]\n",
    "        test_y = y.loc[test_start:test_end]\n",
    "\n",
    "    else:\n",
    "        if test_end + 1 >= len(X):\n",
    "            train_x = X.loc[train_start:train_end-1]\n",
    "            train_y = y.loc[train_start:train_end-1]\n",
    "        else:\n",
    "            train_x = pd.concat([X.loc[train_start:train_end-1], X.loc[test_end+1:]])\n",
    "            train_y = pd.concat([y.loc[train_start:train_end-1], y.loc[test_end+1:]])\n",
    "\n",
    "        test_x = X.loc[test_start:test_end]\n",
    "        test_y = y.loc[test_start:test_end]\n",
    "    \n",
    "    overlapping_sets = list(set(train_x['case:concept:name'].unique()).intersection(set(test_x['case:concept:name'].unique())))\n",
    "    # # Clean train\n",
    "    X_train = train_x[train_x['case:concept:name'].isin([overlapping_sets]) == False]\n",
    "    y_train = train_y[train_y['case:concept:name'].isin(train_x['case:concept:name'].unique())]\n",
    "    \n",
    "    # # Clean test\n",
    "    X_validation = test_x[test_x['case:concept:name'].isin([overlapping_sets]) == False]\n",
    "    y_validation = test_y[test_y['case:concept:name'].isin(test_x['case:concept:name'].unique())]\n",
    "\n",
    "    # # Finalizing the data\n",
    "    X_train = X_train[X_features[:-1]].values\n",
    "    X_validation = X_validation[X_features[:-1]].values\n",
    "    y_train = y_train[y_features[0]].values\n",
    "    y_validation = y_validation[y_features[0]].values\n",
    "    \n",
    "    # Define a function to optimize using Hyperopt\n",
    "    def objective(params):\n",
    "        xgb = RandomForestRegressor(**params, n_jobs = -1)\n",
    "        xgb.fit(X_train, np.ravel(y_train))\n",
    "        score = xgb.score(X_validation, y_validation)\n",
    "        return {'loss': -score, 'status': STATUS_OK}\n",
    "    \n",
    "    # Define Trials object to store optimization results\n",
    "    trials = Trials()\n",
    "    \n",
    "    # Use Hyperopt to find the best hyperparameters\n",
    "    best = fmin(objective, space, algo=tpe.suggest, max_evals=10, trials=trials, return_argmin=False)\n",
    "    \n",
    "    # Store the best parameters and corresponding score\n",
    "    best_params_rfr_list.append(best)\n",
    "    best_scores_list.append(-trials.best_trial['result']['loss'])  # Convert back to positive\n",
    "    \n",
    "    \n",
    "    test_end = test_start\n",
    "    train_end -= step_size\n",
    "    test_start = train_end\n",
    "\n",
    "#Print the best parameters and average score across all outer folds\n",
    "print(\"Best Parameters:\")\n",
    "for params in best_params_rfr_list:\n",
    "    print(params)\n",
    "print(\"Average Score:\", np.mean(best_scores_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving time models in pickle format\n",
    "count = 1\n",
    "for i in best_params_rfr_list:\n",
    "    model = RandomForestRegressor(**i)\n",
    "    \n",
    "    model.fit(X[X_features_to_train].values, np.ravel(y[y_features_to_train].values))\n",
    "    print(model.score(X_test[X_features_to_train].values, y_test[y_features_to_train].values))\n",
    "    print(f'MAE: {round(mean_absolute_error(np.exp(y_test[y_features_to_train].values), np.exp(model.predict(X_test[X_features_to_train].values)))/3600,3)} hours')\n",
    "    \n",
    "    pickle.dump(model , open(f'next_activity_time_prediction_rfr_{count}.pk1' , 'wb'))\n",
    "    count+=1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the search space for hyperparameters\n",
    "space = {\n",
    "    'n_estimators': hp.choice('n_estimators', [int(x) for x in np.linspace(start = 5, stop = 50, num = 45)]),\n",
    "    'max_depth': hp.choice('max_depth', [int(i) for i in range(2,20)]),\n",
    "    'learning_rate': hp.uniform('learning_rate', 0.01, 0.6),\n",
    "    'subsample': hp.uniform('subsample', 0.6, 1.0),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.6, 1.0),\n",
    "    'gamma': hp.uniform('gamma', 0, 0.2),\n",
    "}\n",
    "\n",
    "# Initialize variables to store results\n",
    "best_params_xgbr_list = []\n",
    "best_scores_list = []\n",
    "\n",
    "n = 10\n",
    "\n",
    "start = 0\n",
    "end = len(X)\n",
    "step_size = end//n\n",
    "\n",
    "train_start = 0 \n",
    "train_end = end - step_size\n",
    "\n",
    "test_start = train_end\n",
    "test_end = end\n",
    "\n",
    "for i in range(n):\n",
    "    if train_start == test_start:\n",
    "        train_x = X.loc[test_end+1:]\n",
    "        train_y = y.loc[test_end+1:]\n",
    "\n",
    "        test_x = X.loc[test_start:test_end]\n",
    "        test_y = y.loc[test_start:test_end]\n",
    "\n",
    "    else:\n",
    "        if test_end + 1 >= len(X):\n",
    "            train_x = X.loc[train_start:train_end-1]\n",
    "            train_y = y.loc[train_start:train_end-1]\n",
    "        else:\n",
    "            train_x = pd.concat([X.loc[train_start:train_end-1], X.loc[test_end+1:]])\n",
    "            train_y = pd.concat([y.loc[train_start:train_end-1], y.loc[test_end+1:]])\n",
    "\n",
    "        test_x = X.loc[test_start:test_end]\n",
    "        test_y = y.loc[test_start:test_end]\n",
    "    \n",
    "    overlapping_sets = list(set(train_x['case:concept:name'].unique()).intersection(set(test_x['case:concept:name'].unique())))\n",
    "    # # Clean train\n",
    "    X_train = train_x[train_x['case:concept:name'].isin([overlapping_sets]) == False]\n",
    "    y_train = train_y[train_y['case:concept:name'].isin(train_x['case:concept:name'].unique())]\n",
    "    \n",
    "    # # Clean test\n",
    "    X_validation = test_x[test_x['case:concept:name'].isin([overlapping_sets]) == False]\n",
    "    y_validation = test_y[test_y['case:concept:name'].isin(test_x['case:concept:name'].unique())]\n",
    "\n",
    "    # # Finalizing the data\n",
    "    X_train = X_train[X_features[:-1]].values\n",
    "    X_validation = X_validation[X_features[:-1]].values\n",
    "    y_train = y_train[y_features[0]].values\n",
    "    y_validation = y_validation[y_features[0]].values\n",
    "    \n",
    "\n",
    "    # Define a function to optimize using Hyperopt\n",
    "    def objective(params):\n",
    "        xgb = XGBRegressor(**params, n_jobs = -1)\n",
    "        xgb.fit(X_train, y_train)\n",
    "        score = xgb.score(X_validation, y_validation)\n",
    "        return {'loss': -score, 'status': STATUS_OK}\n",
    "    \n",
    "    # Define Trials object to store optimization results\n",
    "    trials = Trials()\n",
    "    \n",
    "    # Use Hyperopt to find the best hyperparameters\n",
    "    best = fmin(objective, space, algo=tpe.suggest, max_evals=20, trials=trials, return_argmin=False)\n",
    "    \n",
    "    # Store the best parameters and corresponding score\n",
    "    best_params_xgbr_list.append(best)\n",
    "    best_scores_list.append(-trials.best_trial['result']['loss'])  # Convert back to positive\n",
    "    \n",
    "    \n",
    "    test_end = test_start\n",
    "    train_end -= step_size\n",
    "    test_start = train_end\n",
    "\n",
    "#Print the best parameters and average score across all outer folds\n",
    "print(\"Best Parameters:\")\n",
    "for params in best_params_xgbr_list:\n",
    "    print(params)\n",
    "print(\"Average Score:\", np.mean(best_scores_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving time models in pickle format\n",
    "count = 1\n",
    "for i in best_params_xgbr_list:\n",
    "    model = XGBRegressor(**i)\n",
    "    model.fit(X[X_features_to_train].values, np.ravel(y[y_features_to_train].values))\n",
    "    print(model.score(X_test[X_features_to_train].values, y_test[y_features_to_train].values))\n",
    "\n",
    "    print(f'MAE on logged values (used to get a better smoothing): {round(mean_absolute_error(np.exp(y_test[y_features_to_train].values), np.exp(model.predict(X_test[X_features_to_train].values)))/3600,3)} hours')\n",
    "    pickle.dump(model, open(f'next_activity_time_prediction_xgbr_{count}.pk1', 'wb'))\n",
    "    count += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
